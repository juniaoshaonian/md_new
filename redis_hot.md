# Redis 热点问题

Redis 的热点问题，是指 Redis 中某个 key 的 QPS 过高，怎么办。Redis 的热点key问题，在实践中是一个很容易遇到的问题，所以也是一个面试中经常考察的点。


## 如何解决热点问题

### 引入本地缓存

第一个方案是引入本地缓存，引入本地缓存之后热点大概率命中本地缓存，就能极大的减轻 Redis 的压力。本地缓存会进一步加剧数据一致性的问题。

### 缓存多份

第二个方案就是缓存多份，比如 test_key 是一个热点，那么可以将同样的内容写入到 test_key0，test_key1..., 而后业务在查询的时候，使用轮训或者随机访问其中一个key。这种方式适用于读操作较多的场景，会加剧数据的不一致性。

### 拆分 key

这是治本之道，比如原本有一个 key 对应的 list 放了100w数据，那么可以拆分成100个 key ，每个key 存放1w数据。

#### 拆分方式
在 Redis 这个场景，要考虑不同数据结构分 key 怎么分，假定这里都分成10个 key 。基本的拆分思路有两个：
- 按照哈希来拆分，例如 list 中元素值是103，那么拆分后他应该在 103%3=3 key3中。如果是哈希结构，则按照哈希结构的 key 来进一步哈希拆分
- 按照值的范围来拆分。例如list中元素的值是 103 ，那么拆分他应该在 [100,200] 这一段中，假设是 key1。

除了这些通用的拆分方法，还有一些独特的拆分方法
- 按照业务来拆分。比如说一个 User 的全部存储在一个哈希结构里面，你就可以将基本信息，登录信息拆分成两个 key；
- 按照 QPS 来分。比如说 list 中有 10w 个元素，你要拆成 10 个 key，你就要保证这个 10 个 key 的 QPS 是接近的，而不是直接平均分 10w；

一般看自己拆分的 key 是否合理，就是拆分后的 key 是否依旧存在热点问题。大多数时候是多拆分一些 key，这样可以充分应对数据增长和 QPS 增长。还有就是要让这些 key 均匀分散在 Redis 的节点，这一点可以通过手动计算 CRC16 得到槽，再经过映射关系来确定是否均匀分配。

## 有亮点的面试方案

### 背景说明
这个面试方案一个是大数据、高性能、高并发榜单的解决方案。结合了上面本地缓存和拆分 key 的方法。他不在谈及 Redis 热点的时候引用这个方案，也可以作为你项目的一个难点。彰显你对高并发、高性能的独到理解。

### 实现思路
![未命名文件 (1).jpg](..%2FDocuments%2Fgithub_recovery_code%2F%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6%20%281%29.jpg)
整个实现思路很简单，假设我们分 key 之后的 key 形式是 my_biz:%d，假设我们只要榜单前 100：

- 使用 N 个 zset 来存储所有的榜单数据。这里假设是使用 10 个 key；
- 根据业务主键除以分 key 的数量，得到 key 的后缀。例如说 id 为 3，那么它的数据在 my_biz:3 这个 key 对应的 zset 上；
- 定时任务每 1 分钟会从这 N 个 key 里面各取前 100，而后借助归并排序计算全局的前 100。用比喻来说，就好比有 10 个班，我每个班取前 100 名，而后排序再取前 100 名，这 100 名就是全级排名；
- 定时任务会把这 top100 的数据同步到各个节点的本地缓存中
- 查询前 100 会直接命中本地缓存。

这里有一些细节问题需要注意：

- 在更新的时候要注意顺序问题。举个例子来说，如果针对同一个数据，一个要更新热度为 100，一个要更新热度为 101，你要小心并发问题。最好就是在 ZADD 的命令里面再加上一个 GT 选项；
- zset 并不是真的要存储全部的数据，你可以只存储一部分，这个要业务来判定。比如说业务上说的是计算七天内的榜单数据，例如说只有七天内的文章才可以上榜，那么你的 zset 里面就只需要维护七天内的数据；
- 这里的分 key 方式，除了上面提到的使用 hash，也可以用日期来分。比如说每天一个 key，这样在只需要七天数据参与排行的情况下，可以等 key 自然过期。例如说设置 key 的过期时间是七天，那么七天之后这个 key 就不在了，你也不需要访问了；
- 从理论上来说，这 10 个 key 应该在经过 CRC16 计算和槽映射之后，应该均匀分散在 Redis Cluster 不同集群上；
- 当新的业务节点上线的时候，再次计算一下全局前 100，而后这个新节点才能对外提供服务；

从性能角度来说，最主要的就是直接命中了本地缓存。

从高可用的角度来说，即便整个 Redis 集群全崩了，也可以靠着本地缓存撑住。

### 参考话术
我们站在一个演进的角度来阐述

<blockquote> 
我设计过一个解决大数据、高可用、高性能的榜单方案。一开始我们业务的数据量不是很大，所以直接用了最简单的 Redis zset 来计算榜单。
</blockquote>
<blockquote> 
后面随着业务的发展，计算这个榜单的数据越来越多，并发量越来越高。这个时候，一个 zset 里面要放几百万个数据，存储这个 zset 的 Redis 并发极高，压力极大。并且 zset 中元素数量太多，导致更新的时候越来越慢。
</blockquote>
<blockquote> 
发现这个问题之后，我就综合业务实际情况，设计了一个新的榜单解决方案 —— 拆分 key 的方案。
</blockquote>
<blockquote> 
首先，我根据数据量，将原本单一的 key 拆分成了 10 个key，比如说 my_biz:0, my_biz:1 这种。</blockquote>
<blockquote> 
其次，key 的后缀是业务 ID 除以 10 的余数，在更新热度可以只更新对应的 key。
</blockquote>

<blockquote> 
第三，启动一个定时任务，这个定时任务会定期从所有的 key 里面各取前 100 名，而后用归并排序计算出来全局的前 100 名。
</blockquote>

<blockquote> 
第四，定时任务还会把计算的结果同步到所有的节点的本地缓存上。
</blockquote>

<blockquote> 
最终业务查询榜单的时候，就直接命中本地缓存，性能极好。
</blockquote>

## 总结
Redis热点问题有三种解决思路：本地缓存、缓存多份、拆分key。最后我给出了一个亮点方案。结合本地缓存，拆分key的方法解决了高性能，高并发大数据榜单问题。