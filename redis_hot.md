# Redis 热点问题

Redis 的热点问题是指某个节点的 QPS 过高导致性能瓶颈，常见于以下场景：
1. 电商秒杀场景中商品库存 key 的频繁扣减
2. 社交平台热点话题的实时点赞/阅读统计
3. 游戏排行榜单的实时更新查询
4. 新闻热点事件的缓存数据高频访问

这个问题是面试中重点考察的高频考点。很容易回答出来，但是不容易刷出亮点。因为基本的一些槽迁移啥的，这种比较容易想到，但是你需要有一些特别的骚操作才能赢得竞争优势。


# 数据倾斜问题

这里首先说明一下数据倾斜问题一般是指某个地方的数据要比别的地方多。具体到 Redis 这里，就是 Redis 的某些节点上的数据明显比别的节点多。而正常来说，数据倾斜了，QPS 也倾斜了。所以这些比较多数据的节点，QPS 也会更高。所以这些节点面临 CPU、内存、网络带宽等多方面的问题。

而且，如果是QPS很高在业内就叫热点问题。所以有人问你数据倾斜问题，你也可以参照热点问题的思路去回答。相应的如果有人问你某个 Redis 节点的Qps 过高该怎么办，也类似。

# 如何解决热点问题
所有的热点问题的最核心的解决思路就一个：分而治之。按照这个思路我们在 Redis 这个场景中可以从两个角度去解决

解决热点问题需要分两个层面处理：
1. **节点级热点**：将集中在一个节点上的多个Key均匀分布到集群
2. **Key级热点**：对单个高频访问的Key进行拆分

就像处理演唱会入场：先让观众分散到多个入口（节点级分流），如果某个入口仍然拥挤，就增加检票通道（Key拆分）。

## 节点级热点
把这些集中的数据重新打散，分散到别的地方。

### 业务数据隔离
**核心思路**：
将某一个热门业务单独分隔出来，不让他影响其他业务。举个例子来说，如果 User 和 Order 共用一个 Redis Cluster，然后 User 导致某个节点数据倾斜了，那么可以将 User 改为使用另外一个 Redis Cluster；   

### 槽迁移
**核心思路**：
增加节点，将热点节点上的数据，迁移到其他节点上。

一般情况，挑一个业务低峰期。 使用 Redis Cluster 的rebalance 命令，简单好用，让他自行去平衡。当我们需要对槽进行更精确的控制，也可以自己手动进行分配


### 重新设计 key 结构：
举个例子，假设说原本的 key 结构是 user:$id，那么可以考虑改改前缀，比如说 /my/company/user/$id。

虽然你看上去只是改了前缀，但是经过 CRC16 之后算出来的哈希值跟原版会有很大差异；

### 手动哈希一次：

例如说 user:$id 是原始的 key，你可以改为用 user:md5($id) 来作为key，也可以用 md5
(user:$id)，小心设计不要重复了。当然你可以把 md5 换成别的算法，核心就是经过手动哈希之后，你的 key 落到节点上
会更加均匀；


## Key级热点
单个热点key如何解决，这个在中高级岗位中考察较多。回答这个问题，最好的装逼方式就是讨论拆分 key，并且进一步给出具体的案例作为佐证

### 引入本地缓存
第一个方案是引入本地缓存，引入本地缓存之后热点大概率命中本地缓存，就能极大的减轻 Redis 的压力。本地缓存会进一步加剧数据一致性的问题。

### 缓存多份
第二个方案就是缓存多份，比如 test_key 是一个热点，那么可以将同样的内容写入到 test_key0，test_key1..., 而后业务在查询的时候，使用轮训或者随机访问其中一个key。这种方式适用于读操作较多的场景，会加剧数据的不一致性。

注意这些 key 需要均匀的分布在不同的节点上。

### 拆分 key

这是治本之道，比如原本有一个 key 对应的 list 放了100w数据，那么可以拆分成100个 key ，每个key 存放1w数据。

#### 拆分方式
在 Redis 这个场景，要考虑不同数据结构分 key 怎么分，假定这里都分成10个 key 。基本的拆分思路有两个：
- 按照哈希来拆分，例如 list 中元素值是103，那么拆分后他应该在 103%3=3 key3中。如果是哈希结构，则按照哈希结构的 key 来进一步哈希拆分
- 按照值的范围来拆分。例如list中元素的值是 103 ，那么拆分他应该在 [100,200] 这一段中，假设是 key1。

除了这些通用的拆分方法，还有一些独特的拆分方法
- 按照业务来拆分。比如说一个 User 的全部存储在一个哈希结构里面，你就可以将基本信息，登录信息拆分成两个 key；
- 按照 QPS 来分。比如说 list 中有 10w 个元素，你要拆成 10 个 key，你就要保证这个 10 个 key 的 QPS 是接近的，而不是直接平均分 10w；

一般看自己拆分的 key 是否合理，就是拆分后的 key 是否依旧存在热点问题。大多数时候是多拆分一些 key，这样可以充分应对数据增长和 QPS 增长。还有就是要让这些 key 均匀分散在 Redis 的节点，这一点可以通过手动计算 CRC16 得到槽，再经过映射关系来确定是否均匀分配。

## 高并发高性能榜单方案

### 背景说明
这个面试方案一个是大数据、高性能、高并发榜单的解决方案。结合了上面本地缓存和拆分 key 的方法。不仅可以在谈及 Redis 热点的时候引用这个方案，也可以作为你项目的一个难点。彰显你对高并发、高性能的独到理解。

### 使用场景

通常来说，你在简历里写擅长设计高性能，高可用的缓存方案或者设计过高性能高可用的榜单方案， 就可以用这个案例作为证据。遇到这些问题你就可以用这个案例来回答：
- 你的项目有什么难点？
- 你做过什么令人印象深刻的事情？
- 你觉得你做得最好的点是什么？

如果面试官问到了有关缓存、Redis、Redis zset 这些问题，你也可以使用这个案例
- 你有设计过缓存方案吗？这个方案总的来说还是很强的
- 你用过 zset 吗？ 

而榜单问题本身就是一个面试热点，所以这个问题也能显著帮到你，换句话来说，只要面试官问你怎么解决排行榜之类的问题，你就可以用这个案例。


### 实现思路

整个实现思路很简单，假设我们分 key 之后的 key 形式是 my_biz:%d，假设我们只要榜单前 100：

- 使用 N 个 zset 来存储所有的榜单数据。这里假设是使用 10 个 key；
- 根据业务主键除以分 key 的数量，得到 key 的后缀。例如说 id 为 3，那么它的数据在 my_biz:3 这个 key 对应的 zset 上；
- 定时任务每 1 分钟会从这 N 个 key 里面各取前 100，而后借助归并排序计算全局的前 100。用比喻来说，就好比有 10 个班，我每个班取前 100 名，而后排序再取前 100 名，这 100 名就是全级排名；
- 定时任务会把这 top100 的数据同步到各个节点的本地缓存中
- 查询前 100 会直接命中本地缓存。

这里有一些细节问题需要注意：

- 在更新的时候要注意顺序问题。举个例子来说，如果针对同一个数据，一个要更新热度为 100，一个要更新热度为 101，你要小心并发问题。最好就是在 ZADD 的命令里面再加上一个 GT 选项；
- zset 并不是真的要存储全部的数据，你可以只存储一部分，这个要业务来判定。比如说业务上说的是计算七天内的榜单数据，例如说只有七天内的文章才可以上榜，那么你的 zset 里面就只需要维护七天内的数据；
- 这里的分 key 方式，除了上面提到的使用 hash，也可以用日期来分。比如说每天一个 key，这样在只需要七天数据参与排行的情况下，可以等 key 自然过期。例如说设置 key 的过期时间是七天，那么七天之后这个 key 就不在了，你也不需要访问了；
- 从理论上来说，这 10 个 key 应该在经过 CRC16 计算和槽映射之后，应该均匀分散在 Redis Cluster 不同集群上；
- 当新的业务节点上线的时候，再次计算一下全局前 100，而后这个新节点才能对外提供服务；
- 为什么定时任务要1分钟，这其实是一个经验值，主要是根据产品要求来确定的。如果产品说这个榜单三分钟刷新一次，那么设置为 3 分钟都可以。如果要是产品说实时查询，就不能用定时任务了，只能直接查询 zset。在这种情况下，需要考虑扩大 Redis 集群，不然撑不住高并发。

从性能角度来说，最主要的就是直接命中了本地缓存。

从高可用的角度来说，即便整个 Redis 集群全崩了，也可以靠着本地缓存撑住。

### 参考话术
我们站在一个演进的角度来阐述

<blockquote> 
我设计过一个解决大数据、高可用、高性能的榜单方案。一开始我们业务的数据量不是很大，所以直接用了最简单的 Redis zset 来计算榜单。
</blockquote>
<blockquote> 
后面随着业务的发展，计算这个榜单的数据越来越多，并发量越来越高。这个时候，一个 zset 里面要放几百万个数据，存储这个 zset 的 Redis 并发极高，压力极大。并且 zset 中元素数量太多，导致更新的时候越来越慢。
</blockquote>
<blockquote> 
发现这个问题之后，我就综合业务实际情况，设计了一个新的榜单解决方案 —— 拆分 key 的方案。
</blockquote>
<blockquote> 
首先，我根据数据量，将原本单一的 key 拆分成了 10 个key，比如说 my_biz:0, my_biz:1 这种。</blockquote>
<blockquote> 
其次，key 的后缀是业务 ID 除以 10 的余数，在更新热度可以只更新对应的 key。
</blockquote>

<blockquote> 
第三，启动一个定时任务，这个定时任务会定期从所有的 key 里面各取前 100 名，而后用归并排序计算出来全局的前 100 名。
</blockquote>

<blockquote> 
第四，定时任务还会把计算的结果同步到所有的节点的本地缓存上。
</blockquote>

<blockquote> 
最终业务查询榜单的时候，就直接命中本地缓存，性能极好。
</blockquote>


## 总结

最后我来总结一下

解决热点问题，或者是数据倾斜问题的核心思路就是分而治之 。

先从节点出发，将一个节点上的数据打散到各个节点上，常见的有业务数据隔离，槽迁移。后面的重新设计 key 结构和手动哈希是比较奇诡的做法，但是能刷出亮点。

然后如何处理单一的热点key，常见的方法有本地缓存，缓存多分，拆分key。其中拆分key是最能体现你的竞争力。

最后我提到了一个大数据，高性能，高并发的榜单方案。他结合了本地缓存，和拆分key的方式。能使你在面试获得巨大优势，在你落地这个方案的时候需要注意并发问题。
