# Redis 热点问题

Redis 的热点问题，是指 Redis 中某个 key 的 QPS 过高，怎么办。Redis 的热点key问题，在实践中是一个很容易遇到的问题，所以也是一个面试中经常考察的点。

## 数据倾斜问题

这里首先说明一下数据倾斜问题一般是指某个地方的数据要比别的地方多。具体到 Redis 这里，就是 Redis 的某些节点上的数据明显比别的节点多。而正常来说，数据倾斜了，QPS 也倾斜了。所以这些比较多数据的节点，QPS 也会更高。所以这些节点面临 CPU、内存、网络带宽等多方面的问题。

而且，如果是QPS很高在业内就叫热点问题。所以

## 如何解决热点问题

### 引入本地缓存

第一个方案是引入本地缓存，引入本地缓存之后热点大概率命中本地缓存，就能极大的减轻 Redis 的压力。本地缓存会进一步加剧数据一致性的问题。

### 缓存多份

第二个方案就是缓存多份，比如 test_key 是一个热点，那么可以将同样的内容写入到 test_key0，test_key1..., 而后业务在查询的时候，使用轮训或者随机访问其中一个key。这种方式适用于读操作较多的场景，会加剧数据的不一致性。

### 拆分 key

这是治本之道，比如原本有一个 key 对应的 list 放了100w数据，那么可以拆分成100个 key ，每个key 存放1w数据。

#### 拆分方式
在 Redis 这个场景，要考虑不同数据结构分 key 怎么分，假定这里都分成10个 key 。基本的拆分思路有两个：
- 按照哈希来拆分，例如 list 中元素值是103，那么拆分后他应该在 103%3=3 key3中。如果是哈希结构，则按照哈希结构的 key 来进一步哈希拆分
- 按照值的范围来拆分。例如list中元素的值是 103 ，那么拆分他应该在 [100,200] 这一段中，假设是 key1。

除了这些通用的拆分方法，还有一些独特的拆分方法
- 按照业务来拆分。比如说一个 User 的全部存储在一个哈希结构里面，你就可以将基本信息，登录信息拆分成两个 key；
- 按照 QPS 来分。比如说 list 中有 10w 个元素，你要拆成 10 个 key，你就要保证这个 10 个 key 的 QPS 是接近的，而不是直接平均分 10w；

一般看自己拆分的 key 是否合理，就是拆分后的 key 是否依旧存在热点问题。大多数时候是多拆分一些 key，这样可以充分应对数据增长和 QPS 增长。还有就是要让这些 key 均匀分散在 Redis 的节点，这一点可以通过手动计算 CRC16 得到槽，再经过映射关系来确定是否均匀分配。

## 有亮点的面试方案

### 背景说明
这个面试方案一个是大数据、高性能、高并发榜单的解决方案。结合了上面本地缓存和拆分 key 的方法。他不在谈及 Redis 热点的时候引用这个方案，也可以作为你项目的一个难点。彰显你对高并发、高性能的独到理解。

### 实现思路
![未命名文件 (1).jpg](..%2FDocuments%2Fgithub_recovery_code%2F%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6%20%281%29.jpg)
整个实现思路很简单，假设我们分 key 之后的 key 形式是 my_biz:%d，假设我们只要榜单前 100：

- 使用 N 个 zset 来存储所有的榜单数据。这里假设是使用 10 个 key；
- 根据业务主键除以分 key 的数量，得到 key 的后缀。例如说 id 为 3，那么它的数据在 my_biz:3 这个 key 对应的 zset 上；
- 定时任务每 1 分钟会从这 N 个 key 里面各取前 100，而后借助归并排序计算全局的前 100。用比喻来说，就好比有 10 个班，我每个班取前 100 名，而后排序再取前 100 名，这 100 名就是全级排名；
- 定时任务会把这 top100 的数据同步到各个节点的本地缓存中
- 查询前 100 会直接命中本地缓存。

这里有一些细节问题需要注意：

- 在更新的时候要注意顺序问题。举个例子来说，如果针对同一个数据，一个要更新热度为 100，一个要更新热度为 101，你要小心并发问题。最好就是在 ZADD 的命令里面再加上一个 GT 选项；
- zset 并不是真的要存储全部的数据，你可以只存储一部分，这个要业务来判定。比如说业务上说的是计算七天内的榜单数据，例如说只有七天内的文章才可以上榜，那么你的 zset 里面就只需要维护七天内的数据；
- 这里的分 key 方式，除了上面提到的使用 hash，也可以用日期来分。比如说每天一个 key，这样在只需要七天数据参与排行的情况下，可以等 key 自然过期。例如说设置 key 的过期时间是七天，那么七天之后这个 key 就不在了，你也不需要访问了；
- 从理论上来说，这 10 个 key 应该在经过 CRC16 计算和槽映射之后，应该均匀分散在 Redis Cluster 不同集群上；
- 当新的业务节点上线的时候，再次计算一下全局前 100，而后这个新节点才能对外提供服务；

从性能角度来说，最主要的就是直接命中了本地缓存。

从高可用的角度来说，即便整个 Redis 集群全崩了，也可以靠着本地缓存撑住。

### 参考话术
我们站在一个演进的角度来阐述

<blockquote> 
我设计过一个解决大数据、高可用、高性能的榜单方案。一开始我们业务的数据量不是很大，所以直接用了最简单的 Redis zset 来计算榜单。
</blockquote>
<blockquote> 
后面随着业务的发展，计算这个榜单的数据越来越多，并发量越来越高。这个时候，一个 zset 里面要放几百万个数据，存储这个 zset 的 Redis 并发极高，压力极大。并且 zset 中元素数量太多，导致更新的时候越来越慢。
</blockquote>
<blockquote> 
发现这个问题之后，我就综合业务实际情况，设计了一个新的榜单解决方案 —— 拆分 key 的方案。
</blockquote>
<blockquote> 
首先，我根据数据量，将原本单一的 key 拆分成了 10 个key，比如说 my_biz:0, my_biz:1 这种。</blockquote>
<blockquote> 
其次，key 的后缀是业务 ID 除以 10 的余数，在更新热度可以只更新对应的 key。
</blockquote>

<blockquote> 
第三，启动一个定时任务，这个定时任务会定期从所有的 key 里面各取前 100 名，而后用归并排序计算出来全局的前 100 名。
</blockquote>

<blockquote> 
第四，定时任务还会把计算的结果同步到所有的节点的本地缓存上。
</blockquote>

<blockquote> 
最终业务查询榜单的时候，就直接命中本地缓存，性能极好。
</blockquote>



### 解决思路

所有数据倾斜的问题解决思路只有一个：分而治之。也就是将这些集中的数据，分散到别的地方。

那么在redis这里，按照这个思路。我们大致可以分为两步

- 将某台节点上集中的Redis key分散到多个节点 
  - 挪走一部分业务数据。举个例子来说，如果 User 和 Order 共用一个 Redis Cluster，然后 User 导致某个节点数据倾斜了，那么可以将 User 改为使用另外一个 Redis Cluster；
  - 槽迁移：挑一个业务低峰期，执行 Redis Cluster 的 rebalance，简单好用，优先使用。当然也可以自己手动分配槽，而后迁移走槽
  - 重新设计 key 结构：举个例子，假设说原本的 key 结构是 user:$id，那么可以考虑改改前缀，比如说 /my/company/user/$id。虽然你看上去只是改了前缀，但是经过 CRC16 之后算出来的哈希值跟原版会有很大差异；
  - 手动哈希一次：例如说 user:$id 是原始的 key，你可以改为用 user:md5($id) 来作为key，也可以用 md(user:$id)，小心设计不要重复了。当然你可以把 md5 换成别的算法，核心就是经过手动哈希之后，你的 key 落到节点上会更加均匀；

- 将某一个
  - 

- 挪走一部分业务数据。举个例子来说，如果 User 和 Order 共用一个 Redis Cluster，然后 User 导致某个节点数据倾斜了，那么可以将 User 改为使用另外一个 Redis Cluster；
- 槽迁移：挑一个业务低峰期，执行 Redis Cluster 的 rebalance，简单好用，优先使用。当然也可以自己手动分配槽，而后迁移走槽
- 重新设计 key 结构：举个例子，假设说原本的 key 结构是 user:$id，那么可以考虑改改前缀，比如说 /my/company/user/$id。虽然你看上去只是改了前缀，但是经过 CRC16 之后算出来的哈希值跟原版会有很大差异；
- 手动哈希一次：例如说 user:$id 是原始的 key，你可以改为用 user:md5($id) 来作为key，也可以用 md(user:$id)，小心设计不要重复了。当然你可以把 md5 换成别的算法，核心就是经过手动哈希之后，你的 key 落到节点上会更加均匀；
- 拆分 key。也就是如果数据迁移是因为某些大的数据结构造成的，比如说 user:all 这个 key 放了 1000w 个元素，那么可以考虑 拆分成 user:all_0, user:all_1... user:all_n 多个key，那么这些 key 大概率不会都落在同一个节点上；






## 总结
Redis热点问题有三种解决思路：本地缓存、缓存多份、拆分key。最后我给出了一个亮点方案。结合本地缓存，拆分key的方法解决了高性能，高并发大数据榜单问题。